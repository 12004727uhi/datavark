{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "global sentence_templates, entity_labels, label_value_options\n",
    "\n",
    "sentence_templates = [\n",
    "    \"The TYPE had 3 COLOR lights around the edges with 1 COLOR light in the middle\",\n",
    "    \"The TYPE was COLOR COLOR\",\n",
    "    \"The TYPE was huge\",\n",
    "    \"It was a COLOR TYPE, with three COLOR lights and a COLOR one in the center\",\n",
    "    \"The TYPE object was glowing COLOR, like a sort of plasma\",\n",
    "    \"There were three COLOR TYPE with a COLOR object behind them\",\n",
    "    \"There were 10 COLOR TYPE with COLOR lights around the edges\",\n",
    "    \"The TYPE was glowing COLOR\",\n",
    "    \"I saw what looked like a TYPE hovering silently\",\n",
    "]\n",
    "entity_labels = [\"COLOR\", \"TYPE\"]\n",
    "label_value_options = {\n",
    "    \"COLOR\": (\n",
    "        \"red\",\n",
    "        \"green\",\n",
    "        \"blue\",\n",
    "        # \"white\",\n",
    "        # \"silver\",\n",
    "        # \"orange\",\n",
    "        # \"grey\",\n",
    "        # \"gray\",\n",
    "        # \"purple\",\n",
    "        # \"black\",\n",
    "        # \"rainbow\",\n",
    "        # \"pink\",\n",
    "        # \"yellow\",\n",
    "        # \"brown\",\n",
    "    ),\n",
    "    \"TYPE\": (\n",
    "        \"Light\",\n",
    "        \"Boomerang\",\n",
    "        \"Triangle\",\n",
    "        \"Wing\",\n",
    "        \"Crescent\",\n",
    "        \"Chevron\",\n",
    "        \"Disk\",\n",
    "        \"Saucer\",\n",
    "        \"Cylinder\",\n",
    "        \"Pyramid\",\n",
    "        \"Tic tac\",\n",
    "        \"Orb\",\n",
    "        \"Globe\",\n",
    "        \"Round\",\n",
    "        \"Square\",\n",
    "        \"Rectangle\",\n",
    "        \"Cube\",\n",
    "        \"Fireball\",\n",
    "        \"Wheel\",\n",
    "        \"Top\",\n",
    "        \"Cigar\",\n",
    "        \"Pill\",\n",
    "        \"Starlike\",\n",
    "        \"Rod\",\n",
    "        \"Trapezoid\",\n",
    "        \"Diamond\",\n",
    "        \"Lightbulb\",\n",
    "        \"Dome\",\n",
    "        \"Dot\",\n",
    "        \"Sphere\",\n",
    "        \"Saucer\",\n",
    "        \"Flying disk\",\n",
    "        \"disks\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def print_debug(print_output, str):\n",
    "    print(str) if print_output else None\n",
    "\n",
    "\n",
    "def substring_range(text, substring):\n",
    "    ents = []\n",
    "    for i in re.finditer(re.escape(substring.upper()), text):\n",
    "        ents.append((i.start(), i.end()))\n",
    "    return ents\n",
    "\n",
    "\n",
    "def shuffle_and_batch(batch_size, data, print_output):\n",
    "    # {\"classes\": entity_labels, \"annotations\": [sent]}\n",
    "    batches = []\n",
    "    batch = []\n",
    "    all_batches = []\n",
    "    random.shuffle(data)\n",
    "    count = 0\n",
    "    for sent in data:\n",
    "        if count < batch_size:\n",
    "            batch.append(sent)\n",
    "            count += 1\n",
    "        else:\n",
    "            batches.append(batch)\n",
    "            batch = [sent]\n",
    "            count = 1\n",
    "    for b in batches:\n",
    "        print_debug(print_output, f\"\\n{b}\")\n",
    "        all_batches.append({\"classes\": entity_labels, \"annotations\": b})\n",
    "    return all_batches\n",
    "\n",
    "\n",
    "def update_sentence(label, sent, options):\n",
    "    new_sent = \"\"\n",
    "    options_used = set()\n",
    "    for option in options:\n",
    "        new_sent = (new_sent if new_sent else sent).replace(label, option.upper(), 1)\n",
    "        options_used.add(option)\n",
    "        if not label in new_sent:\n",
    "            break\n",
    "    return new_sent, options_used\n",
    "\n",
    "\n",
    "def get_all_for_label(generated_sentences, label_of_interest):\n",
    "    output_for_label = []\n",
    "    for old_gen_sentence in generated_sentences:\n",
    "        label_options_used = set()\n",
    "        options_list = set(label_value_options[label_of_interest])\n",
    "        for option in options_list:\n",
    "            ents = []\n",
    "            options = options_list - label_options_used\n",
    "            if not options:\n",
    "                label_options_used.clear()\n",
    "                to_shuffle = list(label_value_options[label_of_interest])\n",
    "                random.shuffle(to_shuffle)\n",
    "                options_list = set(to_shuffle)\n",
    "                options = options_list\n",
    "            new_sentence, options_used = update_sentence(\n",
    "                label_of_interest, old_gen_sentence[0], options\n",
    "            )\n",
    "            label_options_used.update(options_used)\n",
    "            new_ents = old_gen_sentence[1][\"entities\"] + ents if ents else []\n",
    "            new_ents.sort()\n",
    "            output_for_label.append([new_sentence, {\"entities\": new_ents}])\n",
    "    return output_for_label\n",
    "\n",
    "\n",
    "def find_ents(data, print_output):\n",
    "    sents_with_ents = []\n",
    "    for sent in data:\n",
    "        ents = []\n",
    "        for entity_label in entity_labels:\n",
    "            for label_value in label_value_options[entity_label]:\n",
    "                extracted = substring_range(sent[0], label_value.upper())\n",
    "                if extracted:\n",
    "                    ents.append([extracted[0][0], extracted[0][1], f\"{entity_label}\"])\n",
    "            ents.sort()\n",
    "            sents_with_ents.append([sent[0].lower().capitalize(), {\"entities\": ents}])\n",
    "    print_debug(print_output, f\"\\nSents with ents: {sents_with_ents}\")\n",
    "    return sents_with_ents\n",
    "\n",
    "\n",
    "def generate_annotations(print_output):\n",
    "    for sent in sentence_templates:\n",
    "        output = []\n",
    "        for label in entity_labels:\n",
    "            output = get_all_for_label(\n",
    "                [[sent, {\"entities\": []}]] if not output else output,\n",
    "                label,\n",
    "            )\n",
    "        print_debug(print_output, f\"{len(output)} annotated sentences generated!\")\n",
    "        print_debug(print_output, f\"Output example: {output[0]}\")\n",
    "        yield output\n",
    "\n",
    "\n",
    "def run_generator(batch_size, print_output):\n",
    "    annotations = generate_annotations(print_output)\n",
    "    generated_data = []\n",
    "    for _ in range(\n",
    "        len(sentence_templates)\n",
    "    ):  # change to range(len(sentences)) for all sentences\n",
    "        sent_template_to_batch = next(annotations)\n",
    "        print_debug(\n",
    "            print_output,\n",
    "            f\"\\nSentence to batch & shuffle example: {sent_template_to_batch[0]}\",\n",
    "        )\n",
    "        with_ents = find_ents(sent_template_to_batch, print_output)\n",
    "        training_data = shuffle_and_batch(\n",
    "            batch_size, with_ents, print_output\n",
    "        )  # one sentence of annotations\n",
    "        # print the first generated annotation document to verify success (uncomment)\n",
    "        print_debug(\n",
    "            print_output,\n",
    "            f\"\\nShuffled training data example: {training_data[0]}\",\n",
    "        )\n",
    "        # count the annotated annotated documents in the new corpus\n",
    "        print_debug(\n",
    "            print_output,\n",
    "            f\"\\nThe new training data has {len(training_data)} documents of {batch_size} annotated training lines each\\n\",\n",
    "        )\n",
    "        generated_data.append(training_data)\n",
    "    return generated_data\n",
    "\n",
    "def write_json(path, filename, data):\n",
    "    with open(path + filename + '.json', 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "\n",
    "def make_annotations(print_output):\n",
    "    save_path = './experiment_test_files/train/golds_small/'\n",
    "    filename = 'golds'\n",
    "    batch_size = 5\n",
    "    generated_training_data = run_generator(\n",
    "        batch_size, 0\n",
    "    )  # batch size (int), print debug output? (boolean)\n",
    "    print_debug(print_output, f\"Result: {len(generated_training_data)} sentence annotations, with {len(generated_training_data[0])} batches each.\")\n",
    "    print_debug(print_output, generated_training_data[0])\n",
    "    for s_idx, sent in enumerate(generated_training_data):\n",
    "        for b_idx, batch in enumerate(sent):\n",
    "            write_json(save_path, f'{filename}_{s_idx}_{b_idx}', batch)\n",
    "\n",
    "make_annotations(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('uhi-ZQVV2iWc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65f88eacf3a10b22e2367da6754b23494b2804a02fe03c23afbe72788a968f5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
